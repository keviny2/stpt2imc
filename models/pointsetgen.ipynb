{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "british-tuner",
   "metadata": {},
   "source": [
    "## Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "stainless-supplier",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For plotting\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from skimage import io\n",
    "# For everything\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "# For our model\n",
    "import torchvision.models as models\n",
    "from torchvision import datasets, transforms\n",
    "# For utilities\n",
    "import os, shutil, time\n",
    "import cv2 as cv\n",
    "import subprocess\n",
    "from torch.multiprocessing import Pool, set_start_method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "constant-imaging",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if GPU is available\n",
    "use_gpu = torch.cuda.is_available()\n",
    "torch.backends.cudnn.benchmark = True\n",
    "torch.backends.cudnn.enabled = True\n",
    "\n",
    "# remove .ipynb_chaeckpoint files\n",
    "subprocess.run('.././rm_ipynbcheckpoints.sh', shell=True, cwd='/home/kyang/Shared/Notebooks/Kevin/stpt2imc');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "substantial-agenda",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Block3(nn.Module):\n",
    "    '''\n",
    "    Module consisting of 3 convolutional layers\n",
    "    '''\n",
    "    def __init__(self, in_ch, out_ch, kernel_size=3):\n",
    "        super().__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Conv2d(in_ch, out_ch, kernel_size=kernel_size, stride=2),  # first stride is always 2\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(out_ch),\n",
    "            \n",
    "            nn.Conv2d(out_ch, out_ch, kernel_size=3),  # constant kernel size from here\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(out_ch),\n",
    "            \n",
    "            nn.Conv2d(out_ch, out_ch, kernel_size=3),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(out_ch)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n",
    "\n",
    "    \n",
    "class PointSetGen(nn.Module):\n",
    "    def __init__(self, in_ch=8, batch_size=8):\n",
    "        super().__init__()\n",
    "        self.batch_size = batch_size\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "        # ====== ENCODER 1 ======\n",
    "        \n",
    "        self.beginning = nn.Sequential(\n",
    "            nn.BatchNorm2d(8),\n",
    "            \n",
    "            nn.Conv2d(8, 16, kernel_size=3),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(16),\n",
    "            \n",
    "            nn.Conv2d(16, 16, kernel_size=3),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(16)\n",
    "        )\n",
    "        \n",
    "        self.block3_1 = Block3(16, 32)\n",
    "        self.block3_2 = Block3(32, 64)\n",
    "        self.block3_3 = Block3(64, 128)\n",
    "        self.block3_4 = Block3(128, 256, kernel_size=5)\n",
    "        self.upblock = nn.Sequential(nn.Conv2d(256, 512, kernel_size=1))\n",
    "        \n",
    "        # ====== DECODER 1 ======\n",
    "        \n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(512, 512, kernel_size=3, stride=2),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(512)\n",
    "        )\n",
    "        self.fully_connected1 = nn.Sequential(\n",
    "            nn.Flatten(-2, -1),\n",
    "            nn.Linear(4, 2048),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.deconv1 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(512, 256, kernel_size=5),\n",
    "            nn.Upsample(scale_factor=2),\n",
    "            nn.BatchNorm2d(256)\n",
    "        )\n",
    "        \n",
    "        self.skip1 = nn.Sequential(\n",
    "            nn.Conv2d(512, 256, kernel_size=3),\n",
    "            nn.Upsample((12, 12))\n",
    "        )\n",
    "        self.comb1 = nn.Conv2d(256, 256, kernel_size=3)\n",
    "        self.blue1 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(256, 128, kernel_size=5),\n",
    "            nn.Upsample(scale_factor=2)\n",
    "        )\n",
    "        \n",
    "        self.skip2 = nn.Sequential(\n",
    "            nn.Conv2d(256, 128, kernel_size=3),\n",
    "            nn.Upsample((28, 28))\n",
    "        )\n",
    "        self.comb2 = nn.Conv2d(128, 128, kernel_size=3)\n",
    "        self.blue2 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(128, 64, kernel_size=5),\n",
    "            nn.Upsample(scale_factor=2)\n",
    "        )\n",
    "        \n",
    "        self.skip3 = nn.Sequential(\n",
    "            nn.Conv2d(128, 64, kernel_size=3),\n",
    "            nn.Upsample((60, 60))\n",
    "        )\n",
    "        self.comb3 = nn.Conv2d(64, 64, kernel_size=3)\n",
    "        self.blue3 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(64, 32, kernel_size=5),\n",
    "            nn.Upsample(scale_factor=2)\n",
    "        )   \n",
    "        \n",
    "        self.skip4 = nn.Sequential(\n",
    "            nn.Conv2d(64, 32, kernel_size=3),\n",
    "            nn.Upsample((124, 124))\n",
    "        )\n",
    "        self.comb4 = nn.Conv2d(32, 32, kernel_size=3)\n",
    "        self.blue4 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(32, 16, kernel_size=5),\n",
    "            nn.Upsample(scale_factor=2)\n",
    "        )  \n",
    "        \n",
    "        self.skip5 = nn.Sequential(\n",
    "            nn.Conv2d(32, 16, kernel_size=3),\n",
    "            nn.Upsample((252, 252))\n",
    "        )\n",
    "        self.comb5 = nn.Sequential(\n",
    "            nn.Conv2d(16, 16, kernel_size=3),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.Conv2d(16, 32, kernel_size=3, stride=2)\n",
    "        )\n",
    "        \n",
    "        # ====== ENCODER 2 ======\n",
    "        \n",
    "        self.enc_skip1 = nn.Sequential(\n",
    "            nn.Conv2d(32, 32, kernel_size=3),\n",
    "            nn.Upsample((124, 124))\n",
    "        )\n",
    "        self.enc_comb1 = nn.Sequential(\n",
    "            nn.Conv2d(32, 32, kernel_size=3),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(32),\n",
    "            \n",
    "            nn.Conv2d(32, 64, kernel_size=3, stride=2)\n",
    "        )\n",
    "        \n",
    "        self.enc_skip2 = nn.Sequential(\n",
    "            nn.Conv2d(64, 64, kernel_size=3),\n",
    "            nn.Upsample((60, 60))\n",
    "        )\n",
    "        self.enc_comb2 = nn.Sequential(\n",
    "            nn.Conv2d(64, 64, kernel_size=3),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(64)\n",
    "        )\n",
    "        self.enc_last2 = nn.Conv2d(64, 128, kernel_size=5, stride=2)\n",
    "        \n",
    "        self.enc_skip3 = nn.Sequential(\n",
    "            nn.Conv2d(128, 128, kernel_size=3),\n",
    "            nn.Upsample((27, 27))\n",
    "        )\n",
    "        self.enc_comb3 = nn.Sequential(\n",
    "            nn.Conv2d(128, 128, kernel_size=3),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(128)\n",
    "        )\n",
    "        self.enc_last3 = nn.Conv2d(128, 256, kernel_size=5, stride=2)  \n",
    "        \n",
    "        self.enc_skip4 = nn.Sequential(\n",
    "            nn.Conv2d(256, 256, kernel_size=3),\n",
    "            nn.Upsample((11, 11))\n",
    "        )\n",
    "        self.enc_comb4 = nn.Sequential(\n",
    "            nn.Conv2d(256, 256, kernel_size=3),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(256)\n",
    "        )\n",
    "        self.enc_last4 = nn.Sequential(\n",
    "            nn.Conv2d(256, 512, kernel_size=5, stride=2),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(512)\n",
    "        )\n",
    "        \n",
    "        # ====== PREDICTOR ======\n",
    "\n",
    "        self.fully_connected2 = nn.Linear(2048, 2048)\n",
    "        self.fully_connected3 = nn.Sequential(\n",
    "            nn.Flatten(-2, -1),\n",
    "            nn.Linear(9, 2048)\n",
    "        )\n",
    "\n",
    "        self.dec_blue1 = nn.ConvTranspose2d(512, 256, kernel_size=5, stride=2)\n",
    "        self.dec_skip1 = nn.Sequential(\n",
    "            nn.Conv2d(256, 256, kernel_size=3),\n",
    "            nn.Upsample((9, 9))\n",
    "        )\n",
    "        self.convdeconv1 = nn.Sequential(\n",
    "            nn.Conv2d(256, 256, kernel_size=3),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(256),\n",
    "\n",
    "            nn.ConvTranspose2d(256, 128, kernel_size=5, stride=2),\n",
    "            nn.Upsample(scale_factor=2)\n",
    "        )\n",
    "\n",
    "        self.dec_skip2 = nn.Sequential(\n",
    "            nn.Conv2d(128, 128, kernel_size=3),\n",
    "            nn.Upsample((34, 34))\n",
    "        )\n",
    "        self.convdeconv2 = nn.Sequential(\n",
    "            nn.Conv2d(128, 128, kernel_size=3),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(128),\n",
    "\n",
    "            nn.ConvTranspose2d(128, 64, kernel_size=5, stride=2),\n",
    "            nn.Upsample(scale_factor=2)\n",
    "        )\n",
    "        \n",
    "        self.dec_skip3 = nn.Sequential(\n",
    "            nn.Conv2d(64, 64, kernel_size=3),\n",
    "            nn.Upsample((134, 134))\n",
    "        )\n",
    "        self.convdeconv3 = nn.Sequential(\n",
    "            nn.Conv2d(64, 64, kernel_size=3),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(64),\n",
    "\n",
    "            nn.Conv2d(64, 64, kernel_size=3),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(64)\n",
    "        )\n",
    "        \n",
    "        self.fully_connected4 = nn.Sequential(\n",
    "            nn.Linear(2048, 1024),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            nn.Linear(1024, 300)\n",
    "#             nn.Linear(1024, 49152)\n",
    "        )\n",
    "        \n",
    "        self.finalconv_full = nn.Conv2d(512, 64, kernel_size=1)\n",
    "        self.finalconv_deconv = nn.Sequential(\n",
    "#             nn.Conv2d(64, 512, kernel_size=3),\n",
    "#             nn.Upsample((45, 45))\n",
    "            nn.Upsample((30,30))\n",
    "        )\n",
    "        \n",
    "        self.mlp = nn.Conv2d(64, 40, kernel_size=1)\n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        # ====== ENCODER 1 ======\n",
    "        x = self.beginning(x)\n",
    "        x = self.block3_1(x)\n",
    "        x1 = x    # can do this because torch returns new tensors for operations like nn.Conv2d\n",
    "        \n",
    "        # sequence of blocks of 3 convolutional layers\n",
    "        x = self.block3_2(x) \n",
    "        x2 = x\n",
    "        x = self.block3_3(x) \n",
    "        x3 = x\n",
    "        x = self.block3_4(x) \n",
    "        x4 = x\n",
    "\n",
    "        # substitute for block of 4 conv. layers b/c convolutions make images too small\n",
    "        x = self.upblock(x)\n",
    "        x5 = x\n",
    "        \n",
    "        # ====== DECODER 1 ======\n",
    "        \n",
    "        x = self.conv1(x)\n",
    "        x_additional = self.fully_connected1(x)  # save for fully connected layer\n",
    "        x = self.deconv1(x)\n",
    "        \n",
    "        x5 = self.skip1(x5)\n",
    "        x = self.relu(torch.add(x, x5))  # torch.Size([1, 256, 12, 12])\n",
    "        x = self.relu(self.comb1(x))\n",
    "        x5 = x\n",
    "        x = self.blue1(x)\n",
    "        \n",
    "        x4 = self.skip2(x4)\n",
    "        x = self.relu(torch.add(x, x4))\n",
    "        x = self.relu(self.comb2(x))\n",
    "        x4 = x\n",
    "        x = self.blue2(x)\n",
    "        \n",
    "        x3 = self.skip3(x3)\n",
    "        x = self.relu(torch.add(x, x3))\n",
    "        x = self.relu(self.comb3(x))\n",
    "        x3 = x\n",
    "        x = self.blue3(x)\n",
    "\n",
    "        x2 = self.skip4(x2)\n",
    "        x = self.relu(torch.add(x, x2))\n",
    "        x = self.relu(self.comb4(x))\n",
    "        x2 = x\n",
    "        x = self.blue4(x)   \n",
    "        \n",
    "        x1 = self.skip5(x1)\n",
    "        x = self.relu(torch.add(x, x1))\n",
    "        x = self.comb5(x)\n",
    "        \n",
    "        # ====== ENCODER 2 ======\n",
    "        # the function name and variable names should be off by 1\n",
    "        x2 = self.enc_skip1(x2)\n",
    "        x = self.relu(torch.add(x, x2))\n",
    "        x = self.enc_comb1(x)\n",
    "        \n",
    "        x3 = self.enc_skip2(x3)\n",
    "        x = self.relu(torch.add(x, x3))\n",
    "        x = self.enc_comb2(x)\n",
    "        x3 = x\n",
    "        x = self.enc_last2(x)\n",
    "        \n",
    "        x4 = self.enc_skip3(x4)\n",
    "        x = self.relu(torch.add(x, x4))\n",
    "        x = self.enc_comb3(x)\n",
    "        x4 = x\n",
    "        x = self.enc_last3(x)\n",
    "        \n",
    "        x5 = self.enc_skip4(x5)\n",
    "        x = self.relu(torch.add(x, x5))\n",
    "        x = self.enc_comb4(x)\n",
    "        x5 = x\n",
    "        x = self.enc_last4(x)\n",
    "        \n",
    "        # ====== PREDICTOR ======\n",
    "        \n",
    "        x_additional = self.fully_connected2(x_additional)\n",
    "        x_additional = self.relu(torch.add(x_additional, self.fully_connected3(x)))\n",
    "        \n",
    "        x = self.dec_blue1(x)\n",
    "        x5 = self.dec_skip1(x5)\n",
    "        x = self.relu(torch.add(x, x5))\n",
    "        x = self.convdeconv1(x)\n",
    "        \n",
    "        x4 = self.dec_skip2(x4)\n",
    "        x = self.relu(torch.add(x, x4))\n",
    "        x = self.convdeconv2(x)\n",
    "        \n",
    "        x3 = self.dec_skip3(x3)\n",
    "        x = self.relu(torch.add(x, x3))\n",
    "        x = self.convdeconv3(x)\n",
    "        \n",
    "        x_additional = self.fully_connected4(x_additional) # torch.Size([1, 512, 600])\n",
    "        x_additional = torch.reshape(x_additional, (self.batch_size, 512, 100, 3))\n",
    "        x_additional = self.finalconv_full(x_additional)\n",
    "        x = self.finalconv_deconv(x)\n",
    "        x = torch.reshape(x, (self.batch_size, 64, 300, 3))\n",
    "        x = torch.cat((x_additional, x), 2)\n",
    "    \n",
    "        uv = torch.meshgrid(torch.arange(0, 256), torch.arange(0, 256))\n",
    "        uv = torch.stack(uv).permute(1,2,0).type(torch.uint8).cuda()  # [256, 256, 2]\n",
    "        xy = torch.sum(x.type(torch.float32), dim=1) # [self.batch_size, 40, 875, 3]\n",
    "#         xy = torch.sum(x.squeeze().type(torch.float32), dim=0) # [40, 875, 3]\n",
    "\n",
    "#         img = torch.exp(((uv[None,:,:,0]-xy[:,None,None,0])**2 + (uv[None,:,:,1]-xy[:,None,None,1])**2) / (xy[:,None,None,2]**2 + 1))  # [875,256,256]\n",
    "        img = torch.exp(((uv[None,None,:,:,0]-xy[:,:,None,None,0])**2 + (uv[None,None,:,:,1]-xy[:,:,None,None,1])**2) / (xy[:,:,None,None,2]**2 + 1))  # [875,256,256]\n",
    "#         x = self.mlp(x).squeeze()\n",
    "        x = self.mlp(x)\n",
    "        x = torch.sum(x, dim=-1)\n",
    "        x = x[:,:,:,None,None] * img[:,None,:,:,:]\n",
    "        x = torch.sum(x, dim=2)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "skilled-julian",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1\n",
    "# model = PointSetGen(batch_size=batch_size).double()\n",
    "model = PointSetGen(batch_size=batch_size).double()\n",
    "        \n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# Move model and loss function to GPU\n",
    "if use_gpu: \n",
    "    criterion = criterion.cuda()\n",
    "    model = model.cuda()\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.001, weight_decay=0.01)\n",
    "\n",
    "# https://pytorch.org/tutorials/beginner/saving_loading_models.html#saving-loading-a-general-checkpoint-for-inference-and-or-resuming-training\n",
    "\n",
    "# checkpoint = torch.load('../checkpoints/model-epoch-5-losses-285.453.pth')\n",
    "# model.load_state_dict(checkpoint['model_state_dict'])\n",
    "# optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "# inc = checkpoint['epoch'] + 1 # increment depending on how many epochs we already completed\n",
    "inc = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "wired-imagination",
   "metadata": {},
   "outputs": [],
   "source": [
    "class STPT_IMC_ImageFolder(datasets.ImageFolder):    \n",
    "    \"\"\"\n",
    "    Preprocesses\n",
    "    \"\"\"\n",
    "    def __init__(self, root, transform, bits=8, batch_size=64):\n",
    "        self.root = root\n",
    "        self.transform = transform\n",
    "        self.imc_folder = os.path.join(self.root, 'IMC')\n",
    "        self.stpt_folder = os.path.join(self.root, 'STPT')\n",
    "        self.bits = bits # num bits for each pixel in image\n",
    "        \n",
    "        # length of dataset will be the total number of files contained in all subdirectories inside self.imc_folder\n",
    "        self.num_imgs_per_phys_sec = len(os.listdir(os.path.join(self.imc_folder, '01')))\n",
    "        self.num_imgs = self.num_imgs_per_phys_sec * 15  # 15 physical sections\n",
    "        \n",
    "        self.index_to_phys_sec = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]  # skip phys_sec 16\n",
    "            \n",
    "    def __len__(self):\n",
    "        return self.num_imgs\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        phys_sec = self.index_to_phys_sec[int(np.floor(index / self.num_imgs_per_phys_sec))]  # mod to find physical section\n",
    "                                                         \n",
    "        # ====== GET LIST OF IMAGE FILES ======\n",
    "        stpt_imgs = os.listdir(os.path.join(self.stpt_folder,\n",
    "                                    '{}'.format(str(phys_sec).zfill(2)))) \n",
    "                                                         \n",
    "        imc_imgs = os.listdir(os.path.join(self.imc_folder,\n",
    "                                           '{}'.format(str(phys_sec).zfill(2))))\n",
    "        \n",
    "        # ====== GET IMAGE FILE PATH ======\n",
    "        stpt_path = os.path.join(self.stpt_folder,\n",
    "                                           '{}'.format(str(phys_sec).zfill(2)),\n",
    "                                           stpt_imgs[int(index % self.num_imgs_per_phys_sec)])\n",
    "        \n",
    "        imc_path = os.path.join(self.imc_folder,\n",
    "                                          '{}'.format(str(phys_sec).zfill(2)),\n",
    "                                          imc_imgs[int(index % self.num_imgs_per_phys_sec)])\n",
    "\n",
    "        # make sure the files line up\n",
    "        try:\n",
    "            assert(os.path.basename(stpt_path) == os.path.basename(imc_path))\n",
    "        except:\n",
    "            print('stpt path:', os.path.basename(stpt_path))\n",
    "            print('imc path:', os.path.basename(imc_path))\n",
    "                                       \n",
    "        # ====== LOAD IMAGES ======\n",
    "#         stpt_img = self.transform[0](torch.load(stpt_path))  \n",
    "        stpt_img = torch.load(stpt_path)\n",
    "\n",
    "#         imc_img = self.transform[1](torch.load(imc_path))\n",
    "        imc_img = torch.load(imc_path)     \n",
    "                                                                     \n",
    "        return stpt_img.double(), imc_img.double()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "inside-second",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training\n",
    "stpt_normalize_param = [0.5 for i in range(8)]\n",
    "imc_normalize_param = [0.5 for i in range(40)]\n",
    "transform = [transforms.Normalize(stpt_normalize_param, stpt_normalize_param),\n",
    "              transforms.Normalize(imc_normalize_param, imc_normalize_param)]\n",
    "\n",
    "train_imagefolder = STPT_IMC_ImageFolder(root='../data/train',\n",
    "                                         transform=transform)\n",
    "train_loader = torch.utils.data.DataLoader(train_imagefolder,\n",
    "                                           batch_size=batch_size,\n",
    "                                           shuffle=True)\n",
    "\n",
    "# Validation \n",
    "# val_transforms = transforms.Compose([transforms.Normalize(normalize_param, normalize_param)])\n",
    "val_imagefolder = STPT_IMC_ImageFolder(root='../data/val',\n",
    "                                       transform=transform)\n",
    "val_loader = torch.utils.data.DataLoader(val_imagefolder,\n",
    "                                         batch_size=batch_size,\n",
    "                                         shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ahead-ballot",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AverageMeter(object):\n",
    "  '''A handy class from the PyTorch ImageNet tutorial''' \n",
    "  def __init__(self):\n",
    "    self.reset()\n",
    "    self.vals = []\n",
    "    self.avgs = []\n",
    "  def reset(self):\n",
    "    self.val, self.avg, self.sum, self.count = 0, 0, 0, 0\n",
    "  def update(self, val, n=1):\n",
    "    self.val = val\n",
    "    self.sum += val * n\n",
    "    self.count += n\n",
    "    self.avg = self.sum / self.count\n",
    "    self.vals.append(self.val)\n",
    "    self.avgs.append(self.avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "regulated-charity",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(val_loader, model, criterion, epoch, plot=True):\n",
    "  print('='*10, 'Starting validation epoch {}'.format(epoch), '='*10) \n",
    "  model.eval()\n",
    "\n",
    "  # Prepare value counters and timers\n",
    "  batch_time, data_time, losses = AverageMeter(), AverageMeter(), AverageMeter()\n",
    "\n",
    "  end = time.time()\n",
    "  already_saved_images = False\n",
    "  for i, (stpt, imc) in enumerate(val_loader):\n",
    "    data_time.update(time.time() - end)\n",
    "\n",
    "    # Use GPU\n",
    "    if use_gpu: \n",
    "        stpt, imc = stpt.cuda(), imc.cuda()\n",
    "\n",
    "    # Run model and record loss\n",
    "    imc_recons = model(stpt.double()).cuda() # throw away class predictions\n",
    "    loss = criterion(imc_recons.double(), imc.double())\n",
    "    losses.update(loss.item(), stpt.size(0))\n",
    "\n",
    "    # Record time to do forward passes and save images\n",
    "    batch_time.update(time.time() - end)\n",
    "    end = time.time()\n",
    "\n",
    "    # Print model accuracy -- in the code below, val refers to both value and validation\n",
    "    if i % 25 == 0:\n",
    "      print('Validate: [{0}/{1}]\\t'\n",
    "            'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
    "            'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'.format(\n",
    "             i, len(val_loader), batch_time=batch_time, loss=losses))\n",
    "    \n",
    "  return losses.avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "constitutional-sponsorship",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_loader, model, criterion, optimizer, epoch, plot=True):\n",
    "  print('='*10, 'Starting training epoch {}'.format(epoch), '='*10)\n",
    "  model.train()\n",
    "  \n",
    "  # Prepare value counters and timers\n",
    "  batch_time, data_time, losses = AverageMeter(), AverageMeter(), AverageMeter()\n",
    "\n",
    "  end = time.time()\n",
    "  for i, (stpt, imc) in enumerate(train_loader):\n",
    "    \n",
    "    # Use GPU if available\n",
    "    if use_gpu:\n",
    "        stpt, imc = stpt.cuda(), imc.cuda()\n",
    "\n",
    "    # Record time to load data (above)\n",
    "    data_time.update(time.time() - end)\n",
    "\n",
    "    imc_recons = model(stpt).cuda()\n",
    "    loss = criterion(imc_recons, imc)\n",
    "\n",
    "    losses.update(loss.item(), stpt.size(0))\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # Record time to do forward and backward passes\n",
    "    batch_time.update(time.time() - end)\n",
    "    end = time.time()\n",
    "\n",
    "    # Print model accuracy -- in the code below, val refers to value, not validation\n",
    "    if i % 25 == 0:\n",
    "      print('Epoch: [{0}][{1}/{2}]\\t'\n",
    "            'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
    "            'Data {data_time.val:.3f} ({data_time.avg:.3f})\\t'\n",
    "            'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'.format(\n",
    "              epoch, i, len(train_loader), batch_time=batch_time,\n",
    "             data_time=data_time, loss=losses)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "random-monday",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Starting training epoch 0 ==========\n",
      "Epoch: [0][0/71940]\tTime 1.285 (1.285)\tData 0.123 (0.123)\tLoss nan (nan)\t\n",
      "Epoch: [0][25/71940]\tTime 0.348 (0.390)\tData 0.096 (0.101)\tLoss nan (nan)\t\n",
      "Epoch: [0][50/71940]\tTime 0.377 (0.377)\tData 0.126 (0.106)\tLoss nan (nan)\t\n",
      "Epoch: [0][75/71940]\tTime 0.331 (0.366)\tData 0.079 (0.101)\tLoss nan (nan)\t\n",
      "Epoch: [0][100/71940]\tTime 0.337 (0.360)\tData 0.086 (0.099)\tLoss nan (nan)\t\n",
      "Epoch: [0][125/71940]\tTime 0.344 (0.357)\tData 0.092 (0.097)\tLoss nan (nan)\t\n",
      "Epoch: [0][150/71940]\tTime 0.346 (0.356)\tData 0.094 (0.097)\tLoss nan (nan)\t\n",
      "Epoch: [0][175/71940]\tTime 0.330 (0.354)\tData 0.079 (0.096)\tLoss nan (nan)\t\n",
      "Epoch: [0][200/71940]\tTime 0.335 (0.354)\tData 0.083 (0.098)\tLoss nan (nan)\t\n",
      "Epoch: [0][225/71940]\tTime 0.352 (0.354)\tData 0.101 (0.098)\tLoss nan (nan)\t\n",
      "Epoch: [0][250/71940]\tTime 0.344 (0.353)\tData 0.093 (0.097)\tLoss nan (nan)\t\n",
      "Epoch: [0][275/71940]\tTime 0.441 (0.353)\tData 0.189 (0.098)\tLoss nan (nan)\t\n",
      "Epoch: [0][300/71940]\tTime 0.366 (0.354)\tData 0.114 (0.099)\tLoss nan (nan)\t\n",
      "Epoch: [0][325/71940]\tTime 0.357 (0.354)\tData 0.104 (0.099)\tLoss nan (nan)\t\n",
      "Epoch: [0][350/71940]\tTime 0.333 (0.354)\tData 0.082 (0.099)\tLoss nan (nan)\t\n",
      "Epoch: [0][375/71940]\tTime 0.337 (0.354)\tData 0.085 (0.099)\tLoss nan (nan)\t\n",
      "Epoch: [0][400/71940]\tTime 0.333 (0.356)\tData 0.082 (0.101)\tLoss nan (nan)\t\n",
      "Epoch: [0][425/71940]\tTime 0.356 (0.356)\tData 0.099 (0.101)\tLoss nan (nan)\t\n",
      "Epoch: [0][450/71940]\tTime 0.350 (0.356)\tData 0.099 (0.101)\tLoss nan (nan)\t\n",
      "Epoch: [0][475/71940]\tTime 0.361 (0.356)\tData 0.110 (0.102)\tLoss nan (nan)\t\n",
      "Epoch: [0][500/71940]\tTime 0.336 (0.356)\tData 0.086 (0.102)\tLoss nan (nan)\t\n",
      "Epoch: [0][525/71940]\tTime 0.324 (0.356)\tData 0.073 (0.102)\tLoss nan (nan)\t\n",
      "Epoch: [0][550/71940]\tTime 0.348 (0.355)\tData 0.097 (0.102)\tLoss nan (nan)\t\n",
      "Epoch: [0][575/71940]\tTime 0.331 (0.356)\tData 0.079 (0.103)\tLoss nan (nan)\t\n",
      "Epoch: [0][600/71940]\tTime 0.365 (0.356)\tData 0.113 (0.102)\tLoss nan (nan)\t\n",
      "Epoch: [0][625/71940]\tTime 0.347 (0.356)\tData 0.095 (0.102)\tLoss nan (nan)\t\n",
      "Epoch: [0][650/71940]\tTime 0.334 (0.356)\tData 0.079 (0.102)\tLoss nan (nan)\t\n",
      "Epoch: [0][675/71940]\tTime 0.792 (0.359)\tData 0.541 (0.106)\tLoss nan (nan)\t\n",
      "Epoch: [0][700/71940]\tTime 0.351 (0.363)\tData 0.099 (0.109)\tLoss nan (nan)\t\n",
      "Epoch: [0][725/71940]\tTime 0.391 (0.362)\tData 0.139 (0.109)\tLoss nan (nan)\t\n",
      "Epoch: [0][750/71940]\tTime 0.341 (0.362)\tData 0.089 (0.109)\tLoss nan (nan)\t\n",
      "Epoch: [0][775/71940]\tTime 0.334 (0.362)\tData 0.082 (0.108)\tLoss nan (nan)\t\n",
      "Epoch: [0][800/71940]\tTime 0.351 (0.361)\tData 0.099 (0.108)\tLoss nan (nan)\t\n",
      "Epoch: [0][825/71940]\tTime 0.345 (0.361)\tData 0.093 (0.108)\tLoss nan (nan)\t\n",
      "Epoch: [0][850/71940]\tTime 0.338 (0.360)\tData 0.087 (0.107)\tLoss nan (nan)\t\n",
      "Epoch: [0][875/71940]\tTime 0.323 (0.360)\tData 0.072 (0.107)\tLoss nan (nan)\t\n",
      "Epoch: [0][900/71940]\tTime 0.339 (0.360)\tData 0.087 (0.107)\tLoss nan (nan)\t\n",
      "Epoch: [0][925/71940]\tTime 0.344 (0.360)\tData 0.094 (0.107)\tLoss nan (nan)\t\n",
      "Epoch: [0][950/71940]\tTime 0.343 (0.360)\tData 0.091 (0.107)\tLoss nan (nan)\t\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    best_losses = 1e10\n",
    "    epochs = 20\n",
    "\n",
    "    # Train model\n",
    "    for epoch in range(epochs):\n",
    "      epoch += inc\n",
    "      # Train for one epoch, then validate\n",
    "      train(train_loader, model, criterion, optimizer, epoch)\n",
    "      with torch.no_grad():\n",
    "        losses = validate(val_loader, model, criterion, epoch)\n",
    "      # Save checkpoint and replace old best model if current model is better\n",
    "      if losses < best_losses:\n",
    "        best_losses = losses\n",
    "        torch.save({'model_state_dict': model.state_dict(),\n",
    "                    'optimizer_state_dict': optimizer.state_dict(),\n",
    "                    'loss': losses,\n",
    "                    'epoch': epoch,\n",
    "                    'loss': losses\n",
    "                   }, '../checkpoints/pointsetgen/model-epoch-{}-losses-{:.3f}.pth'.format(epoch+1,losses))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cpsc533y",
   "language": "python",
   "name": "cpsc533y"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
