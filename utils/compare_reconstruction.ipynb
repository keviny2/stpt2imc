{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "jewish-silly",
   "metadata": {},
   "source": [
    "## Pipeline to compare reconstruction to target IMC images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "retained-cricket",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For plotting\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from skimage import io\n",
    "import cv2 as cv\n",
    "# For everything\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "# For our model\n",
    "import torchvision.models as models\n",
    "from torchvision import datasets, transforms\n",
    "from torch.multiprocessing import Pool, set_start_method\n",
    "# For utilities\n",
    "import os, shutil, time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "compatible-wrestling",
   "metadata": {},
   "source": [
    "## UNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cross-table",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code from https://amaarora.github.io/2020/09/13/unet.html#u-net\n",
    "class Block(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_ch, out_ch, 3)\n",
    "        self.relu  = nn.ReLU()\n",
    "        self.conv2 = nn.Conv2d(out_ch, out_ch, 3)\n",
    "        self.batchnorm2d = nn.BatchNorm2d(in_ch)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.batchnorm2d(x)\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu(x)\n",
    "        return self.conv2(x)\n",
    "#         return self.conv2(self.relu(self.conv1(self.batchnorm2d(x))))\n",
    "\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, chs=(8,64,128,256,512,1024)):\n",
    "        super().__init__()\n",
    "        self.enc_blocks = nn.ModuleList([Block(chs[i], chs[i+1]) for i in range(len(chs)-1)])\n",
    "        self.pool       = nn.MaxPool2d(2)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        ftrs = []\n",
    "        for block in self.enc_blocks:\n",
    "            x = block(x)\n",
    "            ftrs.append(x)\n",
    "            x = self.pool(x)\n",
    "        return ftrs\n",
    "\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, chs=(1024, 512, 256, 128, 40)):\n",
    "        super().__init__()\n",
    "        self.chs         = chs\n",
    "        self.upconvs    = nn.ModuleList([nn.ConvTranspose2d(chs[i], chs[i+1], 2, 2) for i in range(len(chs)-1)])\n",
    "        self.dec_blocks = nn.ModuleList([Block(chs[i], chs[i+1]) for i in range(len(chs)-1)]) \n",
    "        \n",
    "    def forward(self, x, encoder_features):\n",
    "        for i in range(len(self.chs)-1):\n",
    "            x        = self.upconvs[i](x)\n",
    "            enc_ftrs = self.crop(encoder_features[i], x)\n",
    "            x        = torch.cat([x, enc_ftrs], dim=1)            \n",
    "            x        = self.dec_blocks[i](x)\n",
    "        return x\n",
    "    \n",
    "    def crop(self, enc_ftrs, x):\n",
    "        _, _, H, W = x.shape\n",
    "        enc_ftrs   = transforms.CenterCrop([H, W])(enc_ftrs)\n",
    "        return enc_ftrs\n",
    "\n",
    "\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self, enc_chs=(8,64,128,256,512,1024), dec_chs=(1024, 512, 256, 128, 64)):\n",
    "        super().__init__()\n",
    "        self.encoder = Encoder(enc_chs)\n",
    "        self.decoder = Decoder(dec_chs)\n",
    "        self.head = nn.Conv2d(dec_chs[-1], 40, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        enc_ftrs = self.encoder(x)\n",
    "        out = self.decoder(enc_ftrs[::-1][0], enc_ftrs[::-1][1:])\n",
    "        out = self.head(out)\n",
    "        out = F.interpolate(out, (256, 256))\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "third-press",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = UNet().double()\n",
    "\n",
    "checkpoint = torch.load('../checkpoints/model-epoch-5-losses-285.453.pth')\n",
    "model.load_state_dict(checkpoint['model_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "published-cooperative",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../data/val/STPT/10/40_35.pt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-d3f44193133d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# load images\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mstpt_piece\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../data/val/STPT/{0}/{1}.pt'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mphys_sec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzfill\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mimc_reconst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstpt_piece\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    579\u001b[0m         \u001b[0mpickle_load_args\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'encoding'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    580\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 581\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    582\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_is_zipfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    583\u001b[0m             \u001b[0;31m# The zipfile reader is going to advance the current file position.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_is_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    231\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'w'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_opener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_open_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../data/val/STPT/10/40_35.pt'"
     ]
    }
   ],
   "source": [
    "phys_sec = '10'   # choose which physical section to reconstruct\n",
    "chunk = '40_35'  # choose which chunk to extract\n",
    "\n",
    "# load images\n",
    "stpt_piece = torch.load('../data/val/STPT/{0}/{1}.pt'.format(phys_sec.zfill(2), chunk))\n",
    "imc_reconst = model(stpt_piece.unsqueeze(0)).squeeze()\n",
    "\n",
    "imc_true = torch.load('../data/val/IMC/{0}/{1}.pt'.format(phys_sec.zfill(2), chunk))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "graduate-speaking",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f76674c8950>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 6 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot sample and target pairs\n",
    "\n",
    "nrows = 3\n",
    "ncols = 2\n",
    "f, axarr = plt.subplots(nrows, ncols)\n",
    "for i in range(nrows):\n",
    "    for j in range(ncols):\n",
    "        axarr[i, j].axis(\"off\")\n",
    "        \n",
    "chs = [5, 15, 35]\n",
    "axarr[0, 0].set_title('Reconstruction', pad=20)\n",
    "axarr[0, 1].set_title('Ground Truth', pad=20)\n",
    "axarr[0, 0].imshow(imc_reconst[chs[0]].detach().numpy(), cmap='gray', vmin=0, vmax=255)\n",
    "axarr[0, 1].imshow(imc_true[chs[0]].detach().numpy(), cmap='gray', vmin=0, vmax=255)\n",
    "axarr[1, 0].imshow(imc_reconst[chs[1]].detach().numpy(), cmap='gray', vmin=0, vmax=255)\n",
    "axarr[1, 1].imshow(imc_true[chs[1]].detach().numpy(), cmap='gray', vmin=0, vmax=255)\n",
    "axarr[2, 0].imshow(imc_reconst[chs[2]].detach().numpy(), cmap='gray', vmin=0, vmax=255)\n",
    "axarr[2, 1].imshow(imc_true[chs[2]].detach().numpy(), cmap='gray', vmin=0, vmax=255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "tired-raise",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save figure with file name corresponding to physical section and chunk\n",
    "\n",
    "f.savefig('../figures/{0}_{1}.png'.format(phys_sec, chunk))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cpsc533y",
   "language": "python",
   "name": "cpsc533y"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
