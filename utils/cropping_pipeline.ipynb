{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "involved-mumbai",
   "metadata": {},
   "source": [
    "## Cropping Images Pipeline\n",
    "### Description\n",
    "Crops image pairs from stpt2imc/data/{IMC, STPT}/ and \n",
    "### Notes\n",
    "- normalize to 8 bits b/c most values are between 0-255 anyways\n",
    "- in process_imc(stpt)_image(), don't convert numpy array to double - it slows things down A LOT (don't know why)\n",
    "- convert tensor to double when using torch.save - MASSIVE speed ups\n",
    "- make a clone of the stpt grid tensor when saving b/c torch.save will save the entire grid for some reason"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "heavy-conspiracy",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "import os, time\n",
    "import numpy as np\n",
    "from skimage import io\n",
    "import cv2 as cv\n",
    "import torch\n",
    "from torch.multiprocessing import Pool, set_start_method\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.utils import save_image\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sustained-participation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====== functions to load an stpt and imc image ====== \n",
    "\n",
    "def process_stpt_image(file_name):\n",
    "    img = io.imread(file_name)\n",
    "    \n",
    "    # normalize image (8 bits)\n",
    "    norm_img = img.copy()\n",
    "    cv.normalize(img, norm_img, alpha=0, beta=2**8 - 1, norm_type=cv.NORM_MINMAX)\n",
    "\n",
    "    # Apply log transformation method\n",
    "    c = (2**8 - 1) / np.log(1 + np.max(norm_img))\n",
    "\n",
    "    log_image = c * (np.log(norm_img + 1))\n",
    "    # Specify the data type so that\n",
    "    # float value will be converted to int\n",
    "    return torch.from_numpy(log_image)\n",
    "\n",
    "def process_imc_image(file_name):\n",
    "    # read image file\n",
    "    img = cv.imread(file_name, cv.IMREAD_UNCHANGED)\n",
    "\n",
    "    # normalize image (8 bits)\n",
    "    norm_img = img.copy()\n",
    "    cv.normalize(img, norm_img, alpha=0, beta=2**8 - 1, norm_type=cv.NORM_MINMAX)\n",
    "\n",
    "    # Apply log transformation method\n",
    "    c = (2**8 - 1) / np.log(1 + np.max(norm_img))\n",
    "\n",
    "    log_image = c * (np.log(norm_img + 1))\n",
    "\n",
    "    # Specify the data type so that\n",
    "    # float value will be converted to int\n",
    "    return torch.from_numpy(log_image)\n",
    "\n",
    "def save_imc(phys_sec, grid, row, column):\n",
    "    # creates directory if doesn't exist\n",
    "    if not(os.path.isdir('processed_data/IMC/{0}'.format(str(phys_sec).zfill(2)))):\n",
    "        os.mkdir('processed_data/IMC/{0}'.format(str(phys_sec).zfill(2)))\n",
    "    torch.save(grid[row][column].double(), 'processed_data/IMC/{0}/{1}_{2}.pt'.format(str(phys_sec).zfill(2),\n",
    "                                                                             str(row).zfill(2),\n",
    "                                                                             str(column).zfill(2)))\n",
    "    \n",
    "def save_stpt(phys_sec, grid, row, column):\n",
    "    # creates directory if doesn't exist\n",
    "    if not(os.path.isdir('processed_data/STPT/{0}'.format(str(phys_sec).zfill(2)))):\n",
    "        os.mkdir('processed_data/STPT/{0}'.format(str(phys_sec).zfill(2)))    \n",
    "    torch.save(grid[row][column].clone().double(), 'processed_data/STPT/{0}/{1}_{2}.pt'.format(str(phys_sec).zfill(2),\n",
    "                                                                             str(row).zfill(2),\n",
    "                                                                             str(column).zfill(2)))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "broadband-quantity",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_imc_images(phys_sec, grid_size=256):\n",
    "    '''\n",
    "    phys_sec = physical section where the image came from\n",
    "    grid_size = how large each cropped image will be\n",
    "    \n",
    "    1. get image paths corresponding to phys_sec\n",
    "    2. concatenate IMC images within folder to form a single 40-channel IMC image\n",
    "    3. crop 16 pixels from each side\n",
    "    4. crop images into 256x256 squares\n",
    "    5. free up memory\n",
    "    6. save processed tensors sequentially\n",
    "    '''\n",
    "    \n",
    "    # ====== GET IMAGE PATHS ======\n",
    "    \n",
    "    imc_section_folder = os.path.join('../data/IMC/',\n",
    "                                      'SECTION_{}'.format(str(phys_sec).zfill(2)))\n",
    "\n",
    "    # get a list of all .tif images inside imc_section_folder\n",
    "    imc_img_paths = [os.path.join(imc_section_folder, imc_img_path)\n",
    "                     for imc_img_path in os.listdir(imc_section_folder)\n",
    "                     if imc_img_path.endswith('.tif')]\n",
    "    \n",
    "    # ====== LOAD IMAGES ======\n",
    "    with Pool(maxtasksperchild=100) as p:\n",
    "        imc_imgs = list(p.imap(process_imc_image, imc_img_paths))\n",
    "\n",
    "    imc_imgs = [torch.unsqueeze(img, 0) for img in imc_imgs] # add an extra dimesion for channel\n",
    "    imc_imgs_cat = torch.cat(imc_imgs, 0) # (40, 18720, 18720)\n",
    "\n",
    "    cropped = imc_imgs_cat[:, 16:18704, 16:18704]  # crop 16 pixels from each side (40, 18688, 18688)\n",
    "\n",
    "    # ====== CONSTRUCT GRID ======\n",
    "    \n",
    "    temp = torch.split(cropped, grid_size, dim=1) # row slices; each slice has shape (40, 256, 18688)\n",
    "    grid = [torch.split(curr, grid_size, dim=2) for curr in temp] # grid is 73x73; each slice has shape (40, 256, 256)\n",
    "\n",
    "    # ====== FREE UP MEMORY ======\n",
    "    \n",
    "    del imc_imgs\n",
    "    del imc_imgs_cat\n",
    "    del cropped\n",
    "    del temp\n",
    "    \n",
    "    # ====== SAVE PROCESSED TENSORS ======\n",
    "    for i in range(len(grid)):\n",
    "        for j in range(len(grid[0])):\n",
    "            save_imc(phys_sec, grid, i, j)\n",
    "    \n",
    "    print('IMC: Done physical section:', phys_sec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "assisted-hybrid",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_stpt_images(phys_sec, grid_size=256):\n",
    "    '''\n",
    "    phys_sec = physical section where the image came from\n",
    "    grid_size = how large each cropped image will be\n",
    "    \n",
    "    1. get image paths corresponding to phys_sec\n",
    "    2. concatenate STPT images within folder to form a single 8-channel STPT image\n",
    "    3. crop 16 pixels from each side\n",
    "    4. crop images into 256x256 squares\n",
    "    5. free up memory\n",
    "    6. save processed tensors sequentially\n",
    "    '''\n",
    "    \n",
    "    # ====== GET IMAGE PATHS ======\n",
    "    \n",
    "    stpt_img_paths = [os.path.join('../data/STPT/',\n",
    "                                   'S{0}_Z{1}.tif'.format(str(phys_sec).zfill(3),\n",
    "                                                      optical_section.zfill(2)))\n",
    "                      for optical_section in ['0', '1']]  \n",
    "    \n",
    "    # ====== LOAD IMAGES ======\n",
    "    stpt_imgs = []\n",
    "    for path in stpt_img_paths:\n",
    "        stpt_imgs.append(process_stpt_image(path))\n",
    "#     with Pool(maxtasksperchild=100) as p:\n",
    "#         stpt_imgs = list(p.imap(process_stpt_image, stpt_img_paths))\n",
    "        \n",
    "    stpt_imgs = [img.permute((2,0,1)) for img in stpt_imgs] # (C,H,W) tensor\n",
    "    stpt_imgs_cat = torch.cat(stpt_imgs, 0) # concatenate two stpt images (8, 20800, 20800)\n",
    "    del stpt_imgs\n",
    "\n",
    "    stpt_imgs_cat = transforms.Resize(18720)(stpt_imgs_cat)  # make STPT img same size as IMC (..., 18720, 18720)\n",
    "    cropped = stpt_imgs_cat[:, 16:18704, 16:18704]  # crop 16 pixels from each side (8, 18688, 18688)\n",
    "\n",
    "    # ====== CONSTRUCT GRID ====== \n",
    "    temp = torch.split(cropped, grid_size, dim=1) # row slices; each slice has shape (8, 256, 18688)\n",
    "    grid = [torch.split(curr, grid_size, dim=2) for curr in temp] # grid is 73x73; each slice has shape (8, 256, 256)\n",
    "\n",
    "    # ====== FREE UP MEMORY ======\n",
    "    del stpt_imgs_cat\n",
    "    del cropped\n",
    "    del temp\n",
    "    \n",
    "    # ====== SAVE PROCESSED TENSORS ======\n",
    "    for i in range(len(grid)):\n",
    "        for j in range(len(grid[0])):\n",
    "            save_stpt(phys_sec, grid, i, j) \n",
    "    \n",
    "    print('STPT: Done physical section:', phys_sec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "balanced-shepherd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# main function\n",
    "\n",
    "for i in range(2, 19): # for loop indices correspond to the physical sections that will be processed (18)\n",
    "    if i == 16:\n",
    "        # skip physical section 16 b/c deprecated\n",
    "        continue\n",
    "    # process_imc_images(i)\n",
    "    process_stpt_images(i)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cpsc533y",
   "language": "python",
   "name": "cpsc533y"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
