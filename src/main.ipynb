{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c8fd3112-b9c7-4026-9f95-9eb84e9d3b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "419bb06d-8847-45a3-85b6-182bc7580621",
   "metadata": {
    "tags": []
   },
   "source": [
    "## CROP IMAGES\n",
    "- Crops image pairs from stpt2imc/data/{IMC, STPT}/ and saves cropped images to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b35e25f0-cf72-4eb0-9187-29e4e3354f75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMC: Done physical section: 10\n",
      "STPT: Done physical section: 10\n"
     ]
    }
   ],
   "source": [
    "from img_processing import crop_imc, crop_stpt\n",
    "\n",
    "for i in range(10, 11): # for loop indices correspond to the physical sections that will be processed (18)\n",
    "    if i == 16:\n",
    "        continue  # physical section 16 is defective\n",
    "    crop_imc(i)\n",
    "    crop_stpt(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d78437c6-ac5e-45af-9e78-2b169687392d",
   "metadata": {},
   "source": [
    "## MODEL TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bb4094cc-c99a-4875-a0d9-d7af267d55ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kevin/miniconda3/envs/dl/lib/python3.8/site-packages/torch/cuda/__init__.py:83: UserWarning: CUDA initialization: The NVIDIA driver on your system is too old (found version 10010). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver. (Triggered internally at  ../c10/cuda/CUDAFunctions.cpp:109.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    }
   ],
   "source": [
    "from models import UNet, PointSetGen\n",
    "from datasets import STPT_IMC_ImageFolder\n",
    "from fitting import train_model, validate_model\n",
    "\n",
    "import os\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ba5c86e2-39ea-42ce-b7cb-c22b47cbe320",
   "metadata": {},
   "outputs": [],
   "source": [
    "use_gpu = torch.cuda.is_available()\n",
    "\n",
    "model = UNet().double()\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "if use_gpu: \n",
    "    model = model.cuda()\n",
    "    criterion = criterion.cuda()\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.1, weight_decay=0.01)\n",
    "\n",
    "########### SPLIT TRAIN AND VAL ###########\n",
    "\n",
    "img_folder = STPT_IMC_ImageFolder(root='processed_data')\n",
    "train_size = math.floor(len(img_folder) * .8)\n",
    "val_size = len(img_folder) - train_size\n",
    "train_data, val_data = torch.utils.data.random_split(img_folder, [train_size, val_size])\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_data,\n",
    "                                           batch_size=64,\n",
    "                                           shuffle=True)\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(val_data,\n",
    "                                         batch_size=64,\n",
    "                                         shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb773261-decb-4387-b732-146d5182b082",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    best_losses = 1e10\n",
    "    epochs = 100\n",
    "\n",
    "    # Train model\n",
    "    prev_chkpt_file = None\n",
    "    for epoch in range(epochs):\n",
    "        # Train for one epoch, then validate\n",
    "        train_model(train_loader, model, criterion, optimizer, epoch, use_gpu=use_gpu, mod=10)\n",
    "        with torch.no_grad():\n",
    "            losses = validate_model(val_loader, model, criterion, epoch, use_gpu=use_gpu, mod=10)\n",
    "        # Save checkpoint and replace old best model if current model is better\n",
    "        if losses < best_losses:\n",
    "            best_losses = losses\n",
    "            chkpt_file = 'checkpoints/model-epoch-{}-losses-{:.3f}.pth'.format(epoch+1,losses)\n",
    "            torch.save({'model_state_dict': model.state_dict(),\n",
    "                        'optimizer_state_dict': optimizer.state_dict(),\n",
    "                        'loss': losses,\n",
    "                        'epoch': epoch,\n",
    "                        'loss': losses\n",
    "                       }, chkpt_file)\n",
    "            \n",
    "            # only keep the best model\n",
    "            if prev_chkpt_file:\n",
    "                os.remove(prev_chkpt_file)\n",
    "                prev_chkpt_file = chkpt_file\n",
    "            else:\n",
    "                prev_chkpt_file = chkpt_file"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl",
   "language": "python",
   "name": "dl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
