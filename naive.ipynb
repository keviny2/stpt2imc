{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "senior-theorem",
   "metadata": {},
   "source": [
    "## Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "positive-praise",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For plotting\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from skimage import io\n",
    "# For everything\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "# For our model\n",
    "import torchvision.models as models\n",
    "from torchvision import datasets, transforms\n",
    "# For utilities\n",
    "import os, shutil, time\n",
    "import cv2 as cv\n",
    "import subprocess\n",
    "from multiprocessing.pool import Pool\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "varying-numbers",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args='./rm_ipynbcheckpoints.sh', returncode=0)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if GPU is available\n",
    "use_gpu = torch.cuda.is_available()\n",
    "# use_gpu = False\n",
    "\n",
    "# remove .ipynb_chaeckpoint files\n",
    "subprocess.run('./rm_ipynbcheckpoints.sh', shell=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "formed-participation",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ColorizationNet(nn.Module):\n",
    "  def __init__(self, input_size=128):\n",
    "    super(ColorizationNet, self).__init__()\n",
    "    MIDLEVEL_FEATURE_SIZE = 128\n",
    "\n",
    "    ## First half: ResNet\n",
    "    resnet = models.resnet18() \n",
    "    # Change first conv layer to accept single-channel (grayscale) input\n",
    "    resnet.conv1 = nn.Conv2d(8, 64, kernel_size=3)\n",
    "    # Extract midlevel features from ResNet-gray\n",
    "    self.midlevel_resnet = nn.Sequential(*list(resnet.children())[0:6])\n",
    "\n",
    "    ## Second half: Upsampling\n",
    "    self.upsample = nn.Sequential(     \n",
    "      nn.Conv2d(MIDLEVEL_FEATURE_SIZE, 128, kernel_size=3, stride=1, padding=1),\n",
    "      nn.BatchNorm2d(128),\n",
    "      nn.ReLU(),\n",
    "      nn.Upsample(scale_factor=2),\n",
    "      nn.Conv2d(128, 64, kernel_size=3, stride=1, padding=1),\n",
    "      nn.BatchNorm2d(64),\n",
    "      nn.ReLU(),\n",
    "      nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1),\n",
    "      nn.BatchNorm2d(64),\n",
    "      nn.ReLU(),\n",
    "      nn.Upsample(scale_factor=2),\n",
    "      nn.Conv2d(64, 32, kernel_size=3, stride=1, padding=1),\n",
    "      nn.BatchNorm2d(32),\n",
    "      nn.ReLU(),\n",
    "      nn.Conv2d(32, 2, kernel_size=3, stride=1, padding=1),\n",
    "      nn.Upsample(scale_factor=2)\n",
    "    )\n",
    "\n",
    "  def forward(self, input):\n",
    "\n",
    "    # Pass input through ResNet-gray to extract features\n",
    "    print('the input for the forward pass has shape:', input.shape)\n",
    "    midlevel_features = self.midlevel_resnet(input)\n",
    "    \n",
    "    print('midlevel_features has shape:', midlevel_features)\n",
    "\n",
    "    # Upsample to get colors\n",
    "    output = self.upsample(midlevel_features)\n",
    "    print('output has shape:', output)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "innovative-better",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ColorizationNet().double()\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-2, weight_decay=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "hungarian-biotechnology",
   "metadata": {},
   "outputs": [],
   "source": [
    "class STPT_IMC_ImageFolder(datasets.ImageFolder):    \n",
    "    \"\"\"\n",
    "    Preprocesses\n",
    "    \"\"\"\n",
    "    def __init__(self, root, transform, bits=8, batch_size=64):\n",
    "        self.root = root\n",
    "        self.transform = transform\n",
    "        self.imc_folder = os.path.join(self.root, 'IMC')\n",
    "        self.stpt_folder = os.path.join(self.root, 'STPT')\n",
    "        self.bits = bits # num bits for each pixel in image\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "    def __len__(self):\n",
    "        # length of dataset dictated by num aligned IMC images b/c len(IMC) < len(STPT)\n",
    "        return len(os.listdir(self.imc_folder))\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        # ====== LOAD IMC IMAGES ======\n",
    "        # define folder paths for physical section defined by index\n",
    "        imc_section_folder = os.path.join(self.imc_folder,\n",
    "                                          'SECTION_{}'.format(str(index).zfill(2)))\n",
    "        \n",
    "        # get a list of all .tif images inside imc_section_folder\n",
    "        imc_img_paths = [os.path.join(imc_section_folder, imc_img_path)\n",
    "                         for imc_img_path in os.listdir(imc_section_folder)\n",
    "                         if imc_img_path.endswith('.tif')]\n",
    "        \n",
    "        # load imc images\n",
    "        start = time.time()\n",
    "        with Pool(maxtasksperchild=100) as p_imc:\n",
    "            imc_imgs = list(p_imc.imap(self.process_imc_image, imc_img_paths))\n",
    "        end = time.time()\n",
    "        print('Loading IMC images took', end-start, 'seconds')\n",
    "            \n",
    "        imc_imgs = [torch.unsqueeze(img, 0) for img in imc_imgs] # add an extra dimesion for channel\n",
    "        imc_imgs = torch.cat(imc_imgs, 0) # (40, 18720, 18720)\n",
    "        \n",
    "        \n",
    "        # ====== LOAD STPT IMAGES ======\n",
    "        # get path to images\n",
    "        stpt_img_paths = [os.path.join(self.stpt_folder,\n",
    "                                       'S{0}_Z{1}.tif'.format(str(index).zfill(3),\n",
    "                                                          optical_section.zfill(2)))\n",
    "                          for optical_section in ['0', '1']] \n",
    "        \n",
    "        print('STPT paths:', stpt_img_paths)\n",
    "        \n",
    "        # load stpt images\n",
    "        start = time.time()\n",
    "        with Pool(maxtasksperchild=100) as p_stpt:\n",
    "            stpt_imgs = list(p_stpt.imap(self.process_stpt_image, stpt_img_paths))\n",
    "        end = time.time()\n",
    "        print('Loading STPT images took', end-start, 'seconds')\n",
    "        \n",
    "        stpt_imgs = [img.permute((2,0,1)) for img in stpt_imgs] # (C,H,W) tensor\n",
    "        stpt_imgs = torch.cat(stpt_imgs, 0) # concatenate two stpt images (8, 20800, 20800)\n",
    "        \n",
    "        \n",
    "        # ====== TRANSFORMS ======\n",
    "        \n",
    "        transforms.Resize(imc_imgs.shape[1])(stpt_imgs)  # make STPT img same size as IMC (..., 18720, 18720)\n",
    "        combine = torch.cat((imc_imgs, stpt_imgs), 0) # combine imc and stpt -> (48, 18720, 18720)\n",
    "        \n",
    "        # obtain a batch of random crops\n",
    "        img_set = [self.transform(combine) for i in range(len(self.batch_size))]\n",
    "            \n",
    "        # separate imc and stpt -> (40, 18720, 18720), (8, 18720, 18720)\n",
    "        imc_imgs = [torch.split(img, 40)[0] for img in img_set]\n",
    "        stpt_imgs = [torch.split(img, 40)[1] for img in img_set]\n",
    "        \n",
    "        return stpt_imgs, imc_imgs\n",
    "    \n",
    "    def process_stpt_image(self, file_name):\n",
    "        img = io.imread(file_name)\n",
    "        return torch.from_numpy(img)\n",
    "    \n",
    "    def process_imc_image(self, file_name):\n",
    "        # read image file\n",
    "        img = cv.imread(file_name, cv.IMREAD_UNCHANGED)\n",
    "\n",
    "        # normalize image\n",
    "        norm_img = img.copy()\n",
    "        cv.normalize(img, norm_img, alpha=0, beta=2**self.bits - 1, norm_type=cv.NORM_MINMAX)\n",
    "\n",
    "        # Apply log transformation method\n",
    "        c = (2**self.bits - 1) / np.log(1 + np.max(norm_img))\n",
    "        \n",
    "        log_image = c * (np.log(norm_img + 1))\n",
    "        \n",
    "        # Specify the data type so that\n",
    "        # float value will be converted to int\n",
    "        return torch.from_numpy(log_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "electrical-policy",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_cropped_images(batch):\n",
    "    \"\"\"\n",
    "    takes in a batch of cropped images from a single physical section and forms\n",
    "    a mini-batch for the DataLoader class\n",
    "    \"\"\"\n",
    "    imgs, targets = zip(*batch)\n",
    "    return torch.cat(imgs), torch.cat(targets)\n",
    "\n",
    "# Training\n",
    "train_transforms = transforms.Compose([transforms.RandomCrop(256)])\n",
    "train_imagefolder = STPT_IMC_ImageFolder(root='data/train',\n",
    "                                         transform=train_transforms)\n",
    "train_loader = torch.utils.data.DataLoader(train_imagefolder,\n",
    "                                           batch_size=1,\n",
    "                                           shuffle=True,\n",
    "                                           collate_fn=merge_cropped_images)\n",
    "\n",
    "# Validation \n",
    "# val_transforms = transforms.Compose([transforms.Resize(256)])\n",
    "# val_imagefolder = STPT_IMC_ImageFolder(root='data/val', transform=val_transforms)\n",
    "# val_loader = torch.utils.data.DataLoader(val_imagefolder, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "parliamentary-somalia",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AverageMeter(object):\n",
    "  '''A handy class from the PyTorch ImageNet tutorial''' \n",
    "  def __init__(self):\n",
    "    self.reset()\n",
    "  def reset(self):\n",
    "    self.val, self.avg, self.sum, self.count = 0, 0, 0, 0\n",
    "  def update(self, val, n=1):\n",
    "    self.val = val\n",
    "    self.sum += val * n\n",
    "    self.count += n\n",
    "    self.avg = self.sum / self.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "periodic-artist",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(val_loader, model, criterion, epoch):\n",
    "  print('Starting validation epoch {}'.format(epoch)) \n",
    "  model.eval()\n",
    "\n",
    "  # Prepare value counters and timers\n",
    "  batch_time, data_time, losses = AverageMeter(), AverageMeter(), AverageMeter()\n",
    "\n",
    "  end = time.time()\n",
    "  already_saved_images = False\n",
    "  for i, (stpt, imc) in enumerate(val_loader):\n",
    "    data_time.update(time.time() - end)\n",
    "\n",
    "    # Use GPU\n",
    "    if use_gpu: \n",
    "        stpt, imc = stpt.cuda(), imc.cuda()\n",
    "\n",
    "    # Run model and record loss\n",
    "    imc_recons = model(stpt) # throw away class predictions\n",
    "    loss = criterion(imc_recons, imc)\n",
    "    losses.update(loss.item(), stpt.size(0))\n",
    "\n",
    "    # Record time to do forward passes and save images\n",
    "    batch_time.update(time.time() - end)\n",
    "    end = time.time()\n",
    "\n",
    "    # Print model accuracy -- in the code below, val refers to both value and validation\n",
    "    if i % 25 == 0:\n",
    "      print('Validate: [{0}/{1}]\\t'\n",
    "            'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
    "            'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'.format(\n",
    "             i, len(val_loader), batch_time=batch_time, loss=losses))\n",
    "\n",
    "  print('Finished validation.')\n",
    "  return losses.avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "chemical-vehicle",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_loader, model, criterion, optimizer, epoch):\n",
    "  print('Starting training epoch {}'.format(epoch))\n",
    "  model.train()\n",
    "  \n",
    "  # Prepare value counters and timers\n",
    "  batch_time, data_time, losses = AverageMeter(), AverageMeter(), AverageMeter()\n",
    "\n",
    "  end = time.time()\n",
    "  for i, (stpt, imc) in enumerate(train_loader):\n",
    "    print('Training iteration {}'.format(i))\n",
    "    \n",
    "    # Use GPU if available\n",
    "    if use_gpu: \n",
    "        print('Using GPU!')\n",
    "        stpt, imc = stpt.cuda(), imc.cuda()\n",
    "    else:\n",
    "        print('Not using GPU!')\n",
    "\n",
    "    # Record time to load data (above)\n",
    "    data_time.update(time.time() - end)\n",
    "\n",
    "    # Run forward pass\n",
    "    imc_recons = model(stpt.double())   # DEBUG: make model dimensions work for stpt (currently still using dimensions from tutorial)\n",
    "    loss = criterion(imc_recons, imc) \n",
    "    losses.update(loss.item(), stpt.size(0))\n",
    "\n",
    "    # Compute gradient and optimize\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # Record time to do forward and backward passes\n",
    "    batch_time.update(time.time() - end)\n",
    "    end = time.time()\n",
    "\n",
    "    # Print model accuracy -- in the code below, val refers to value, not validation\n",
    "    if i % 25 == 0:\n",
    "      print('Epoch: [{0}][{1}/{2}]\\t'\n",
    "            'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
    "            'Data {data_time.val:.3f} ({data_time.avg:.3f})\\t'\n",
    "            'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'.format(\n",
    "              epoch, i, len(train_loader), batch_time=batch_time,\n",
    "             data_time=data_time, loss=losses)) \n",
    "\n",
    "  print('Finished training epoch {}'.format(epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "polished-utilization",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training epoch 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process ForkPoolWorker-122:\n"
     ]
    }
   ],
   "source": [
    "# Move model and loss function to GPU\n",
    "if use_gpu: \n",
    "  criterion = criterion.cuda()\n",
    "  model = model.cuda()\n",
    "\n",
    "best_losses = 1e10\n",
    "epochs = 20\n",
    "\n",
    "# Train model\n",
    "for epoch in range(epochs):\n",
    "  # Train for one epoch, then validate\n",
    "  train(train_loader, model, criterion, optimizer, epoch)\n",
    "  with torch.no_grad():\n",
    "    losses = validate(val_loader, model, criterion, epoch)\n",
    "  # Save checkpoint and replace old best model if current model is better\n",
    "  if losses < best_losses:\n",
    "    best_losses = losses\n",
    "    torch.save(model.state_dict(), 'checkpoints/model-epoch-{}-losses-{:.3f}.pth'.format(epoch+1,losses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "optional-amsterdam",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cpsc533y",
   "language": "python",
   "name": "cpsc533y"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
