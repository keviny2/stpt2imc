{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "polar-rebecca",
   "metadata": {},
   "source": [
    "## Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "literary-sensitivity",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For plotting\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from skimage import io\n",
    "# For everything\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "# For our model\n",
    "import torchvision.models as models\n",
    "from torchvision import datasets, transforms\n",
    "# For utilities\n",
    "import os, shutil, time\n",
    "import cv2 as cv\n",
    "import subprocess\n",
    "from torch.multiprocessing import Pool, set_start_method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "alternative-consent",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if GPU is available\n",
    "use_gpu = torch.cuda.is_available()\n",
    "\n",
    "# remove .ipynb_chaeckpoint files\n",
    "subprocess.run('./rm_ipynbcheckpoints.sh', shell=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aggregate-flower",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code from https://amaarora.github.io/2020/09/13/unet.html#u-net\n",
    "class Block(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_ch, out_ch, 3)\n",
    "        self.relu  = nn.ReLU()\n",
    "        self.conv2 = nn.Conv2d(out_ch, out_ch, 3)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.conv2(self.relu(self.conv1(x)))\n",
    "\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, chs=(8,64,128,256,512,1024)):\n",
    "        super().__init__()\n",
    "        self.enc_blocks = nn.ModuleList([Block(chs[i], chs[i+1]) for i in range(len(chs)-1)])\n",
    "        self.pool       = nn.MaxPool2d(2)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        ftrs = []\n",
    "        for block in self.enc_blocks:\n",
    "            x = block(x)\n",
    "            ftrs.append(x)\n",
    "            x = self.pool(x)\n",
    "        return ftrs\n",
    "\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, chs=(1024, 512, 256, 128, 40)):\n",
    "        super().__init__()\n",
    "        self.chs         = chs\n",
    "        self.upconvs    = nn.ModuleList([nn.ConvTranspose2d(chs[i], chs[i+1], 2, 2) for i in range(len(chs)-1)])\n",
    "        self.dec_blocks = nn.ModuleList([Block(chs[i], chs[i+1]) for i in range(len(chs)-1)]) \n",
    "        \n",
    "    def forward(self, x, encoder_features):\n",
    "        for i in range(len(self.chs)-1):\n",
    "            x        = self.upconvs[i](x)\n",
    "            enc_ftrs = self.crop(encoder_features[i], x)\n",
    "            x        = torch.cat([x, enc_ftrs], dim=1)            \n",
    "            x        = self.dec_blocks[i](x)\n",
    "        return x\n",
    "    \n",
    "    def crop(self, enc_ftrs, x):\n",
    "        _, _, H, W = x.shape\n",
    "        enc_ftrs   = transforms.CenterCrop([H, W])(enc_ftrs)\n",
    "        return enc_ftrs\n",
    "\n",
    "\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self, enc_chs=(8,64,128,256,512,1024), dec_chs=(1024, 512, 256, 128, 64)):\n",
    "        super().__init__()\n",
    "        self.encoder = Encoder(enc_chs)\n",
    "        self.decoder = Decoder(dec_chs)\n",
    "        self.head = nn.Conv2d(dec_chs[-1], 40, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        enc_ftrs = self.encoder(x)\n",
    "        out = self.decoder(enc_ftrs[::-1][0], enc_ftrs[::-1][1:])\n",
    "        out = self.head(out)\n",
    "        out = F.interpolate(out, (256, 256))\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "preceding-neighborhood",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = UNet().double()\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-2, weight_decay=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "wooden-hydrogen",
   "metadata": {},
   "outputs": [],
   "source": [
    "class STPT_IMC_ImageFolder(datasets.ImageFolder):    \n",
    "    \"\"\"\n",
    "    Preprocesses\n",
    "    \"\"\"\n",
    "    def __init__(self, root, transform, bits=8, batch_size=64):\n",
    "        self.root = root\n",
    "        self.transform = transform\n",
    "        self.imc_folder = os.path.join(self.root, 'IMC')\n",
    "        self.stpt_folder = os.path.join(self.root, 'STPT')\n",
    "        self.bits = bits # num bits for each pixel in image\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "    def __len__(self):\n",
    "        # length of dataset dictated by num aligned IMC images b/c len(IMC) < len(STPT)\n",
    "        return len(os.listdir(self.imc_folder))\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        index += 1  # covers the case when index=0\n",
    "        # ====== GET IMAGE PATHS ======\n",
    "        # define folder paths for physical section defined by index\n",
    "        imc_section_folder = os.path.join(self.imc_folder,\n",
    "                                          'SECTION_{}'.format(str(index).zfill(2)))\n",
    "        \n",
    "        # get a list of all .tif images inside imc_section_folder\n",
    "        imc_img_paths = [os.path.join(imc_section_folder, imc_img_path)\n",
    "                         for imc_img_path in os.listdir(imc_section_folder)\n",
    "                         if imc_img_path.endswith('.tif')]\n",
    "        \n",
    "        # get path to stpt images\n",
    "        stpt_img_paths = [os.path.join(self.stpt_folder,\n",
    "                                       'S{0}_Z{1}.tif'.format(str(index).zfill(3),\n",
    "                                                          optical_section.zfill(2)))\n",
    "                          for optical_section in ['0', '1']] \n",
    "        \n",
    "        \n",
    "        # ====== LOAD IMAGES ======\n",
    "        \n",
    "        with Pool(maxtasksperchild=100) as p:\n",
    "            imc_imgs = list(p.imap(self.process_imc_image, imc_img_paths))\n",
    "            stpt_imgs = list(p.imap(self.process_stpt_image, stpt_img_paths))\n",
    "            \n",
    "        # postprocess loaded images\n",
    "        imc_imgs = [torch.unsqueeze(img, 0) for img in imc_imgs] # add an extra dimesion for channel\n",
    "        imc_imgs_cat = torch.cat(imc_imgs, 0) # (40, 18720, 18720)\n",
    "        \n",
    "        stpt_imgs = [img.permute((2,0,1)) for img in stpt_imgs] # (C,H,W) tensor\n",
    "        stpt_imgs_cat = torch.cat(stpt_imgs, 0) # concatenate two stpt images (8, 20800, 20800)\n",
    "        \n",
    "        \n",
    "        # ====== TRANSFORMS ======\n",
    "        \n",
    "        stpt_imgs_cat = transforms.Resize(imc_imgs[0].shape[1])(stpt_imgs_cat)  # make STPT img same size as IMC (..., 18720, 18720)\n",
    "        combine = torch.cat((imc_imgs_cat, stpt_imgs_cat), 0) # combine imc and stpt -> (48, 18720, 18720)\n",
    "        \n",
    "        # obtain a batch of random crops\n",
    "        img_set = [self.transform(combine) for i in range(self.batch_size)]\n",
    "            \n",
    "        # separate imc and stpt -> (40, 18720, 18720), (8, 18720, 18720)\n",
    "        imc_imgs = [torch.split(img, 40)[0] for img in img_set]\n",
    "        stpt_imgs = [torch.split(img, 40)[1] for img in img_set]\n",
    "        \n",
    "        return stpt_imgs, imc_imgs\n",
    "    \n",
    "    def process_stpt_image(self, file_name):\n",
    "        img = io.imread(file_name)\n",
    "        return torch.from_numpy(img.astype('uint8'))\n",
    "    \n",
    "    def process_imc_image(self, file_name):\n",
    "        # read image file\n",
    "        img = cv.imread(file_name, cv.IMREAD_UNCHANGED)\n",
    "\n",
    "        # normalize image\n",
    "        norm_img = img.copy()\n",
    "        cv.normalize(img, norm_img, alpha=0, beta=2**self.bits - 1, norm_type=cv.NORM_MINMAX)\n",
    "\n",
    "        # Apply log transformation method\n",
    "        c = (2**self.bits - 1) / np.log(1 + np.max(norm_img))\n",
    "        \n",
    "        log_image = c * (np.log(norm_img + 1))\n",
    "        \n",
    "        # Specify the data type so that\n",
    "        # float value will be converted to int\n",
    "        return torch.from_numpy(log_image.astype('uint8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cheap-guitar",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_cropped_images(batch):\n",
    "    \"\"\"\n",
    "    takes in a batch of cropped images from a single physical section and forms\n",
    "    a mini-batch for the DataLoader class\n",
    "    \"\"\"\n",
    "    stpt_imgs = batch[0][0]\n",
    "    imc_imgs = batch[0][1]\n",
    "    return torch.stack(stpt_imgs), torch.stack(imc_imgs)\n",
    "\n",
    "# Training\n",
    "train_transforms = transforms.Compose([transforms.RandomCrop(256)])\n",
    "train_imagefolder = STPT_IMC_ImageFolder(root='data/train',\n",
    "                                         transform=train_transforms)\n",
    "train_loader = torch.utils.data.DataLoader(train_imagefolder,\n",
    "                                           batch_size=1,\n",
    "                                           shuffle=True,\n",
    "                                           collate_fn=merge_cropped_images)\n",
    "\n",
    "# Validation \n",
    "# val_transforms = transforms.Compose([transforms.Resize(256)])\n",
    "# val_imagefolder = STPT_IMC_ImageFolder(root='data/val', transform=val_transforms)\n",
    "# val_loader = torch.utils.data.DataLoader(val_imagefolder, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "confused-installation",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AverageMeter(object):\n",
    "  '''A handy class from the PyTorch ImageNet tutorial''' \n",
    "  def __init__(self):\n",
    "    self.reset()\n",
    "  def reset(self):\n",
    "    self.val, self.avg, self.sum, self.count = 0, 0, 0, 0\n",
    "  def update(self, val, n=1):\n",
    "    self.val = val\n",
    "    self.sum += val * n\n",
    "    self.count += n\n",
    "    self.avg = self.sum / self.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "synthetic-enhancement",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(val_loader, model, criterion, epoch):\n",
    "  print('Starting validation epoch {}'.format(epoch)) \n",
    "  model.eval()\n",
    "\n",
    "  # Prepare value counters and timers\n",
    "  batch_time, data_time, losses = AverageMeter(), AverageMeter(), AverageMeter()\n",
    "\n",
    "  end = time.time()\n",
    "  already_saved_images = False\n",
    "  for i, (stpt, imc) in enumerate(val_loader):\n",
    "    data_time.update(time.time() - end)\n",
    "\n",
    "    # Use GPU\n",
    "    if use_gpu: \n",
    "        stpt, imc = stpt.cuda(), imc.cuda()\n",
    "\n",
    "    # Run model and record loss\n",
    "    imc_recons = model(stpt) # throw away class predictions\n",
    "    loss = criterion(imc_recons, imc)\n",
    "    losses.update(loss.item(), stpt.size(0))\n",
    "\n",
    "    # Record time to do forward passes and save images\n",
    "    batch_time.update(time.time() - end)\n",
    "    end = time.time()\n",
    "\n",
    "    # Print model accuracy -- in the code below, val refers to both value and validation\n",
    "    if i % 25 == 0:\n",
    "      print('Validate: [{0}/{1}]\\t'\n",
    "            'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
    "            'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'.format(\n",
    "             i, len(val_loader), batch_time=batch_time, loss=losses))\n",
    "\n",
    "  print('Finished validation.')\n",
    "  return losses.avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "suitable-raising",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_loader, model, criterion, optimizer, epoch):\n",
    "  print('='*10, 'Starting training epoch {}'.format(epoch), '='*10)\n",
    "  model.train()\n",
    "  \n",
    "  # Prepare value counters and timers\n",
    "  batch_time, data_time, losses = AverageMeter(), AverageMeter(), AverageMeter()\n",
    "\n",
    "  end = time.time()\n",
    "  for i, (stpt, imc) in enumerate(train_loader):\n",
    "    print('**Training iteration {}**'.format(i))\n",
    "    \n",
    "    # Use GPU if available\n",
    "    if use_gpu:\n",
    "        stpt, imc = stpt.cuda(), imc.cuda()\n",
    "\n",
    "    # Record time to load data (above)\n",
    "    data_time.update(time.time() - end)\n",
    "\n",
    "    # Run forward pass\n",
    "    imc_recons = model(stpt.double()).cuda()\n",
    "    loss = criterion(imc_recons.double(), imc.double()) \n",
    "    losses.update(loss.item(), stpt.size(0))\n",
    "\n",
    "    # Compute gradient and optimize\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # Record time to do forward and backward passes\n",
    "    batch_time.update(time.time() - end)\n",
    "    end = time.time()\n",
    "\n",
    "    # Print model accuracy -- in the code below, val refers to value, not validation\n",
    "    if i % 25 == 0:\n",
    "      print('Epoch: [{0}][{1}/{2}]\\t'\n",
    "            'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
    "            'Data {data_time.val:.3f} ({data_time.avg:.3f})\\t'\n",
    "            'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'.format(\n",
    "              epoch, i, len(train_loader), batch_time=batch_time,\n",
    "             data_time=data_time, loss=losses)) \n",
    "\n",
    "  print('='*10, 'Finished training epoch {}'.format(epoch), '='*10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "humanitarian-attempt",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move model and loss function to GPU\n",
    "if use_gpu: \n",
    "    criterion = criterion.cuda()\n",
    "    model = model.cuda()\n",
    "\n",
    "model.share_memory();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "transsexual-gentleman",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Starting training epoch 0 ==========\n",
      "**Training iteration 0**\n",
      "Epoch: [0][0/17]\tTime 71.433 (71.433)\tData 67.422 (67.422)\tLoss 569.1596 (569.1596)\t\n",
      "**Training iteration 1**\n",
      "**Training iteration 2**\n",
      "**Training iteration 3**\n",
      "**Training iteration 4**\n",
      "**Training iteration 5**\n",
      "**Training iteration 6**\n",
      "**Training iteration 7**\n",
      "**Training iteration 8**\n",
      "**Training iteration 9**\n",
      "**Training iteration 10**\n",
      "**Training iteration 11**\n",
      "**Training iteration 12**\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process ForkPoolWorker-1710:\n",
      "Process ForkPoolWorker-1793:\n",
      "Process ForkPoolWorker-1749:\n",
      "Process ForkPoolWorker-1794:\n",
      "Process ForkPoolWorker-1731:\n",
      "Process ForkPoolWorker-1740:\n",
      "Traceback (most recent call last):\n",
      "Process ForkPoolWorker-1727:\n",
      "Process ForkPoolWorker-1713:\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Process ForkPoolWorker-1699:\n",
      "Process ForkPoolWorker-1672:\n",
      "Process ForkPoolWorker-1760:\n",
      "Process ForkPoolWorker-1737:\n",
      "Process ForkPoolWorker-1680:\n",
      "Process ForkPoolWorker-1698:\n",
      "Process ForkPoolWorker-1741:\n",
      "Process ForkPoolWorker-1722:\n",
      "Process ForkPoolWorker-1709:\n",
      "Process ForkPoolWorker-1730:\n",
      "Process ForkPoolWorker-1744:\n",
      "Process ForkPoolWorker-1695:\n",
      "Process ForkPoolWorker-1747:\n",
      "Process ForkPoolWorker-1745:\n",
      "Process ForkPoolWorker-1748:\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/pool.py\", line 110, in worker\n",
      "    task = get()\n",
      "Process ForkPoolWorker-1683:\n",
      "Process ForkPoolWorker-1679:\n",
      "Process ForkPoolWorker-1751:\n",
      "Process ForkPoolWorker-1759:\n",
      "Process ForkPoolWorker-1755:\n",
      "Process ForkPoolWorker-1792:\n",
      "Process ForkPoolWorker-1761:\n",
      "Process ForkPoolWorker-1758:\n",
      "Process ForkPoolWorker-1705:\n",
      "Process ForkPoolWorker-1780:\n",
      "Process ForkPoolWorker-1790:\n",
      "Process ForkPoolWorker-1685:\n",
      "Process ForkPoolWorker-1671:\n",
      "Process ForkPoolWorker-1719:\n",
      "Process ForkPoolWorker-1711:\n",
      "Process ForkPoolWorker-1739:\n",
      "Process ForkPoolWorker-1712:\n",
      "Process ForkPoolWorker-1718:\n",
      "Process ForkPoolWorker-1724:\n",
      "Process ForkPoolWorker-1750:\n",
      "Process ForkPoolWorker-1753:\n",
      "Process ForkPoolWorker-1743:\n",
      "Process ForkPoolWorker-1746:\n",
      "Process ForkPoolWorker-1770:\n",
      "Process ForkPoolWorker-1742:\n",
      "Process ForkPoolWorker-1789:\n",
      "Process ForkPoolWorker-1707:\n",
      "Process ForkPoolWorker-1767:\n",
      "Process ForkPoolWorker-1771:\n",
      "Process ForkPoolWorker-1723:\n",
      "Process ForkPoolWorker-1726:\n",
      "Process ForkPoolWorker-1765:\n",
      "Process ForkPoolWorker-1781:\n",
      "Process ForkPoolWorker-1762:\n",
      "Process ForkPoolWorker-1721:\n",
      "Process ForkPoolWorker-1676:\n",
      "Process ForkPoolWorker-1666:\n",
      "Process ForkPoolWorker-1756:\n",
      "Process ForkPoolWorker-1708:\n",
      "Process ForkPoolWorker-1774:\n",
      "Process ForkPoolWorker-1768:\n",
      "Process ForkPoolWorker-1736:\n",
      "Process ForkPoolWorker-1785:\n",
      "Process ForkPoolWorker-1769:\n",
      "Process ForkPoolWorker-1776:\n",
      "Process ForkPoolWorker-1754:\n",
      "Process ForkPoolWorker-1773:\n",
      "Process ForkPoolWorker-1757:\n",
      "Process ForkPoolWorker-1734:\n",
      "Process ForkPoolWorker-1703:\n",
      "Process ForkPoolWorker-1725:\n",
      "Process ForkPoolWorker-1690:\n",
      "Process ForkPoolWorker-1677:\n",
      "Process ForkPoolWorker-1729:\n",
      "Process ForkPoolWorker-1704:\n",
      "Process ForkPoolWorker-1752:\n",
      "Process ForkPoolWorker-1696:\n",
      "Traceback (most recent call last):\n",
      "Process ForkPoolWorker-1732:\n",
      "Process ForkPoolWorker-1733:\n",
      "Process ForkPoolWorker-1720:\n",
      "Process ForkPoolWorker-1763:\n",
      "Process ForkPoolWorker-1782:\n",
      "Process ForkPoolWorker-1788:\n",
      "Process ForkPoolWorker-1777:\n",
      "Process ForkPoolWorker-1669:\n",
      "Process ForkPoolWorker-1674:\n",
      "Process ForkPoolWorker-1735:\n",
      "Process ForkPoolWorker-1693:\n",
      "Process ForkPoolWorker-1689:\n",
      "Process ForkPoolWorker-1772:\n",
      "Process ForkPoolWorker-1684:\n",
      "Process ForkPoolWorker-1701:\n",
      "Process ForkPoolWorker-1665:\n",
      "Process ForkPoolWorker-1673:\n",
      "Process ForkPoolWorker-1694:\n",
      "Process ForkPoolWorker-1686:\n",
      "Process ForkPoolWorker-1691:\n",
      "Process ForkPoolWorker-1667:\n",
      "Process ForkPoolWorker-1791:\n",
      "Process ForkPoolWorker-1681:\n",
      "Process ForkPoolWorker-1697:\n",
      "Process ForkPoolWorker-1668:\n",
      "Process ForkPoolWorker-1687:\n",
      "Process ForkPoolWorker-1678:\n",
      "Process ForkPoolWorker-1682:\n",
      "Process ForkPoolWorker-1702:\n",
      "Process ForkPoolWorker-1670:\n",
      "Process ForkPoolWorker-1675:\n",
      "Process ForkPoolWorker-1688:\n",
      "Process ForkPoolWorker-1738:\n",
      "Process ForkPoolWorker-1706:\n",
      "Process ForkPoolWorker-1764:\n",
      "Process ForkPoolWorker-1783:\n",
      "Process ForkPoolWorker-1779:\n",
      "Process ForkPoolWorker-1784:\n",
      "Process ForkPoolWorker-1775:\n",
      "Process ForkPoolWorker-1766:\n",
      "Process ForkPoolWorker-1786:\n",
      "Process ForkPoolWorker-1778:\n",
      "Process ForkPoolWorker-1787:\n",
      "Process ForkPoolWorker-1728:\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/queues.py\", line 351, in get\n",
      "    with self._rlock:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "KeyboardInterrupt\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/pool.py\", line 110, in worker\n",
      "    task = get()\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/pool.py\", line 110, in worker\n",
      "    task = get()\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/pool.py\", line 110, in worker\n",
      "    task = get()\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/pool.py\", line 110, in worker\n",
      "    task = get()\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/pool.py\", line 110, in worker\n",
      "    task = get()\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/queues.py\", line 351, in get\n",
      "    with self._rlock:\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/pool.py\", line 110, in worker\n",
      "    task = get()\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/queues.py\", line 351, in get\n",
      "    with self._rlock:\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/queues.py\", line 351, in get\n",
      "    with self._rlock:\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/queues.py\", line 351, in get\n",
      "    with self._rlock:\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/queues.py\", line 351, in get\n",
      "    with self._rlock:\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/queues.py\", line 351, in get\n",
      "    with self._rlock:\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Traceback (most recent call last):\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    best_losses = 1e10\n",
    "    epochs = 20\n",
    "\n",
    "    # Train model\n",
    "    for epoch in range(epochs):\n",
    "      # Train for one epoch, then validate\n",
    "      train(train_loader, model, criterion, optimizer, epoch)\n",
    "      with torch.no_grad():\n",
    "        losses = validate(val_loader, model, criterion, epoch)\n",
    "      # Save checkpoint and replace old best model if current model is better\n",
    "      if losses < best_losses:\n",
    "        best_losses = losses\n",
    "        torch.save(model.state_dict(), 'checkpoints/model-epoch-{}-losses-{:.3f}.pth'.format(epoch+1,losses))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cpsc533y",
   "language": "python",
   "name": "cpsc533y"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
